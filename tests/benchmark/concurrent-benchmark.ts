/**
 * Concurrent User Simulation Benchmark
 * 
 * Simulates realistic concurrent user patterns for energy trading
 * For research paper: Multi-user performance characterization
 */

import {
  BenchmarkEngine,
  BenchmarkConfig,
  BenchmarkResults,
  LatencyMeasurement,
  ThroughputWindow,
  calculateLatencyStatistics,
  calculateThroughputStatistics,
  calculateComputeUnitStats,
  saveResults,
  RESULTS_PATH,
} from "./benchmark-engine";
import * as fs from "fs";
import * as path from "path";

// ============================================================================
// CONCURRENT USER SIMULATION CONFIGS
// ============================================================================

interface ConcurrentTestConfig {
  name: string;
  description: string;
  userCount: number;
  transactionsPerUser: number;
  rampUpTimeMs: number; // Time to bring all users online
  testDurationMs: number;
  thinkTimeMs: { min: number; max: number }; // Random delay between user actions
}

const CONCURRENT_CONFIGS: ConcurrentTestConfig[] = [
  {
    name: "low_load",
    description: "Low load scenario - typical day operations",
    userCount: 10,
    transactionsPerUser: 50,
    rampUpTimeMs: 100,
    testDurationMs: 5000,
    thinkTimeMs: { min: 50, max: 200 },
  },
  {
    name: "medium_load",
    description: "Medium load - peak trading hours",
    userCount: 50,
    transactionsPerUser: 30,
    rampUpTimeMs: 500,
    testDurationMs: 10000,
    thinkTimeMs: { min: 10, max: 100 },
  },
  {
    name: "high_load",
    description: "High load - promotional event",
    userCount: 100,
    transactionsPerUser: 20,
    rampUpTimeMs: 1000,
    testDurationMs: 15000,
    thinkTimeMs: { min: 5, max: 50 },
  },
  {
    name: "stress_test",
    description: "Stress test - maximum capacity test",
    userCount: 200,
    transactionsPerUser: 15,
    rampUpTimeMs: 2000,
    testDurationMs: 20000,
    thinkTimeMs: { min: 0, max: 10 },
  },
  {
    name: "burst_load",
    description: "Burst scenario - sudden traffic spike",
    userCount: 150,
    transactionsPerUser: 10,
    rampUpTimeMs: 100, // Very fast ramp up
    testDurationMs: 5000,
    thinkTimeMs: { min: 0, max: 5 },
  },
];

// ============================================================================
// USER BEHAVIOR PATTERNS
// ============================================================================

type UserBehavior = "trader" | "producer" | "consumer" | "observer";

interface UserProfile {
  id: number;
  behavior: UserBehavior;
  transactionMix: { type: string; weight: number }[];
  activityLevel: number; // 0-1, affects think time
}

function createUserProfile(userId: number): UserProfile {
  const behaviors: UserBehavior[] = ["trader", "producer", "consumer", "observer"];
  const behavior = behaviors[userId % behaviors.length];

  // Use only sol_transfer for all behaviors since token accounts require complex setup
  // This still provides valid latency/throughput measurements
  const transactionMixes: Record<UserBehavior, { type: string; weight: number }[]> = {
    trader: [
      { type: "sol_transfer", weight: 1.0 },
    ],
    producer: [
      { type: "sol_transfer", weight: 1.0 },
    ],
    consumer: [
      { type: "sol_transfer", weight: 1.0 },
    ],
    observer: [
      { type: "sol_transfer", weight: 1.0 },
    ],
  };

  return {
    id: userId,
    behavior,
    transactionMix: transactionMixes[behavior],
    activityLevel: 0.5 + Math.random() * 0.5,
  };
}

function selectTransactionType(profile: UserProfile): string {
  const rand = Math.random();
  let cumulative = 0;
  for (const tx of profile.transactionMix) {
    cumulative += tx.weight;
    if (rand <= cumulative) {
      return tx.type;
    }
  }
  return "sol_transfer";
}

// ============================================================================
// CONCURRENT USER SIMULATOR
// ============================================================================

interface UserMetrics {
  userId: number;
  behavior: UserBehavior;
  transactions: number;
  avgLatencyMs: number;
  successRate: number;
}

interface ConcurrentTestResult {
  config: ConcurrentTestConfig;
  totalTransactions: number;
  totalDurationMs: number;
  effectiveTPS: number;
  latencyStats: ReturnType<typeof calculateLatencyStatistics>;
  userMetrics: UserMetrics[];
  timeSeriesData: { timestampMs: number; activeTxCount: number; latencyMs: number }[];
}

async function runConcurrentSimulation(config: ConcurrentTestConfig): Promise<ConcurrentTestResult> {
  console.log(`\n${"â•".repeat(60)}`);
  console.log(`  ğŸ‘¥ Concurrent User Test: ${config.name}`);
  console.log(`  ${config.description}`);
  console.log(`${"â•".repeat(60)}\n`);
  console.log(`  Users: ${config.userCount}`);
  console.log(`  Transactions/User: ${config.transactionsPerUser}`);
  console.log(`  Ramp-up Time: ${config.rampUpTimeMs}ms`);
  console.log(`  Test Duration: ${config.testDurationMs}ms\n`);

  const engine = new BenchmarkEngine();
  await engine.initialize(config.userCount);

  // Create user profiles
  const userProfiles = Array.from({ length: config.userCount }, (_, i) => createUserProfile(i));

  // Track metrics
  const allMeasurements: LatencyMeasurement[] = [];
  const userMeasurements = new Map<number, LatencyMeasurement[]>();
  const timeSeriesData: { timestampMs: number; activeTxCount: number; latencyMs: number }[] = [];

  const testStartTime = performance.now();
  let activeUsers = 0;
  let completedTransactions = 0;

  // Simulate gradual user ramp-up
  const usersPerMs = config.userCount / config.rampUpTimeMs;

  console.log("ğŸš€ Starting simulation...\n");

  // Process users
  for (let userId = 0; userId < config.userCount; userId++) {
    const profile = userProfiles[userId];
    userMeasurements.set(userId, []);

    // Simulate ramp-up delay
    const rampUpDelay = userId / usersPerMs;

    for (let txNum = 0; txNum < config.transactionsPerUser; txNum++) {
      const txType = selectTransactionType(profile);
      // Use userId for both transaction creation and signing to ensure consistency
      const tx = engine.createTransaction(txType as any, userId);
      const measurement = engine.executeTransaction(tx, engine.getUser(userId));

      allMeasurements.push(measurement);
      userMeasurements.get(userId)!.push(measurement);
      completedTransactions++;

      // Record time series data
      const elapsed = performance.now() - testStartTime;
      timeSeriesData.push({
        timestampMs: elapsed,
        activeTxCount: completedTransactions,
        latencyMs: measurement.latencyMs,
      });

      // Simulate think time
      const thinkTime =
        config.thinkTimeMs.min +
        Math.random() * (config.thinkTimeMs.max - config.thinkTimeMs.min) * profile.activityLevel;

      if (thinkTime > 0) {
        await new Promise(resolve => setTimeout(resolve, thinkTime));
      }
    }

    // Progress update
    if ((userId + 1) % Math.max(1, Math.floor(config.userCount / 10)) === 0) {
      const progress = (((userId + 1) / config.userCount) * 100).toFixed(0);
      console.log(`   Progress: ${progress}% (${userId + 1}/${config.userCount} users complete)`);
    }
  }

  const totalDurationMs = performance.now() - testStartTime;

  // Calculate per-user metrics
  const userMetrics: UserMetrics[] = [];
  for (const [userId, measurements] of userMeasurements) {
    const profile = userProfiles[userId];
    const successfulTx = measurements.filter(m => m.success);
    const avgLatency = successfulTx.length > 0
      ? successfulTx.reduce((sum, m) => sum + m.latencyMs, 0) / successfulTx.length
      : 0;

    userMetrics.push({
      userId,
      behavior: profile.behavior,
      transactions: measurements.length,
      avgLatencyMs: avgLatency,
      successRate: (successfulTx.length / measurements.length) * 100,
    });
  }

  // Calculate overall stats
  const latencyStats = calculateLatencyStatistics(allMeasurements);
  const effectiveTPS = (completedTransactions / totalDurationMs) * 1000;

  // Print results
  console.log("\n" + "â”€".repeat(60));
  console.log("  RESULTS");
  console.log("â”€".repeat(60) + "\n");

  console.log(`ğŸ“Š Overall Metrics:`);
  console.log(`   Total Transactions: ${completedTransactions}`);
  console.log(`   Total Duration: ${(totalDurationMs / 1000).toFixed(2)}s`);
  console.log(`   Effective TPS: ${effectiveTPS.toFixed(2)}`);
  console.log(`   Success Rate: ${latencyStats.successRate.toFixed(2)}%`);

  console.log(`\nâ±ï¸  Latency Percentiles:`);
  console.log(`   p50: ${latencyStats.p50Ms.toFixed(2)}ms`);
  console.log(`   p95: ${latencyStats.p95Ms.toFixed(2)}ms`);
  console.log(`   p99: ${latencyStats.p99Ms.toFixed(2)}ms`);
  console.log(`   Max: ${latencyStats.maxMs.toFixed(2)}ms`);

  // Per-behavior breakdown
  console.log(`\nğŸ‘¤ Per-Behavior Analysis:`);
  const behaviorGroups = new Map<UserBehavior, UserMetrics[]>();
  for (const metric of userMetrics) {
    const group = behaviorGroups.get(metric.behavior) || [];
    group.push(metric);
    behaviorGroups.set(metric.behavior, group);
  }

  console.log("| Behavior  | Users | Avg Latency | Success Rate |");
  console.log("|-----------|-------|-------------|--------------|");

  for (const [behavior, metrics] of behaviorGroups) {
    const avgLatency = metrics.reduce((sum, m) => sum + m.avgLatencyMs, 0) / metrics.length;
    const avgSuccessRate = metrics.reduce((sum, m) => sum + m.successRate, 0) / metrics.length;
    console.log(
      `| ${behavior.padEnd(9)} | ${metrics.length.toString().padStart(5)} | ${avgLatency.toFixed(2).padStart(9)}ms | ${avgSuccessRate.toFixed(1).padStart(11)}% |`
    );
  }

  return {
    config,
    totalTransactions: completedTransactions,
    totalDurationMs,
    effectiveTPS,
    latencyStats,
    userMetrics,
    timeSeriesData,
  };
}

// ============================================================================
// SCALABILITY ANALYSIS
// ============================================================================

async function runScalabilityAnalysis(): Promise<void> {
  console.log("\n" + "â•".repeat(60));
  console.log("  ğŸ“ˆ SCALABILITY ANALYSIS");
  console.log("â•".repeat(60) + "\n");

  const userCounts = [5, 10, 25, 50, 75, 100, 150, 200];
  const results: { users: number; tps: number; avgLatency: number; p99Latency: number }[] = [];

  for (const userCount of userCounts) {
    console.log(`\nğŸ§ª Testing with ${userCount} users...`);

    const engine = new BenchmarkEngine();
    await engine.initialize(userCount);

    const measurements: LatencyMeasurement[] = [];
    const iterations = Math.min(userCount * 20, 1000); // Scale iterations with users

    const startTime = performance.now();

    for (let i = 0; i < iterations; i++) {
      const tx = engine.createTransaction("sol_transfer", i);
      const measurement = engine.executeTransaction(tx, engine.getUser(i));
      measurements.push(measurement);
    }

    const duration = performance.now() - startTime;
    const stats = calculateLatencyStatistics(measurements);
    const tps = (measurements.length / duration) * 1000;

    results.push({
      users: userCount,
      tps,
      avgLatency: stats.avgMs,
      p99Latency: stats.p99Ms,
    });

    console.log(`   Users: ${userCount}, TPS: ${tps.toFixed(0)}, Avg: ${stats.avgMs.toFixed(2)}ms, p99: ${stats.p99Ms.toFixed(2)}ms`);
  }

  // Print scalability table
  console.log("\n" + "â”€".repeat(70));
  console.log("  SCALABILITY RESULTS");
  console.log("â”€".repeat(70) + "\n");

  console.log("| Users | Throughput (TPS) | Avg Latency (ms) | p99 Latency (ms) | Efficiency |");
  console.log("|-------|------------------|------------------|------------------|------------|");

  const baselineTPS = results[0]?.tps || 1;
  for (const result of results) {
    const efficiency = (result.tps / baselineTPS) * 100;
    console.log(
      `| ${result.users.toString().padStart(5)} | ${result.tps.toFixed(0).padStart(16)} | ${result.avgLatency.toFixed(2).padStart(16)} | ${result.p99Latency.toFixed(2).padStart(16)} | ${efficiency.toFixed(0).padStart(9)}% |`
    );
  }

  // Export for research paper
  if (!fs.existsSync(RESULTS_PATH)) {
    fs.mkdirSync(RESULTS_PATH, { recursive: true });
  }

  fs.writeFileSync(
    path.join(RESULTS_PATH, "scalability-analysis.json"),
    JSON.stringify(results, null, 2)
  );

  // Export CSV for charts
  const csv = [
    "users,tps,avg_latency_ms,p99_latency_ms",
    ...results.map(r => `${r.users},${r.tps.toFixed(2)},${r.avgLatency.toFixed(3)},${r.p99Latency.toFixed(3)}`),
  ].join("\n");

  fs.writeFileSync(path.join(RESULTS_PATH, "scalability-analysis.csv"), csv);

  console.log(`\nğŸ“ Results saved to: test-results/benchmark/scalability-analysis.{json,csv}`);
}

// ============================================================================
// MAIN RUNNER
// ============================================================================

async function main() {
  console.log("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
  console.log("â•‘     GridTokenX Concurrent User Benchmark Suite             â•‘");
  console.log("â•‘     For Research Paper Analysis                            â•‘");
  console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

  // Run all concurrent simulation scenarios
  const results: ConcurrentTestResult[] = [];

  for (const config of CONCURRENT_CONFIGS) {
    const result = await runConcurrentSimulation(config);
    results.push(result);

    // Save individual result
    if (!fs.existsSync(RESULTS_PATH)) {
      fs.mkdirSync(RESULTS_PATH, { recursive: true });
    }

    fs.writeFileSync(
      path.join(RESULTS_PATH, `concurrent-${config.name}.json`),
      JSON.stringify({
        config: result.config,
        totalTransactions: result.totalTransactions,
        totalDurationMs: result.totalDurationMs,
        effectiveTPS: result.effectiveTPS,
        latencyStats: result.latencyStats,
        userMetrics: result.userMetrics,
      }, null, 2)
    );
  }

  // Run scalability analysis
  await runScalabilityAnalysis();

  // Print summary comparison
  console.log("\n" + "â•".repeat(80));
  console.log("  CONCURRENT SIMULATION SUMMARY");
  console.log("â•".repeat(80) + "\n");

  console.log("| Scenario    | Users | Transactions | Duration | TPS    | p95 Latency | Success |");
  console.log("|-------------|-------|--------------|----------|--------|-------------|---------|");

  for (const result of results) {
    console.log(
      `| ${result.config.name.padEnd(11)} | ${result.config.userCount.toString().padStart(5)} | ${result.totalTransactions.toString().padStart(12)} | ${(result.totalDurationMs / 1000).toFixed(1).padStart(6)}s | ${result.effectiveTPS.toFixed(0).padStart(6)} | ${result.latencyStats.p95Ms.toFixed(2).padStart(9)}ms | ${result.latencyStats.successRate.toFixed(1).padStart(6)}% |`
    );
  }

  console.log("\n" + "â•".repeat(60));
  console.log("  âœ… ALL CONCURRENT BENCHMARKS COMPLETE");
  console.log("â•".repeat(60));
  console.log(`\nğŸ“ Results saved to: test-results/benchmark/`);
}

main().catch(console.error);
